{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b622ec",
   "metadata": {},
   "source": [
    "# Tutorial 01: Milvus Basics\n",
    "Welcome to the first tutorial in our Vector Database series! In this notebook, you'll learn how to set up Milvus, create connections, databases, users, collections, and perform basic operations. Let's get started!\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "Before you begin, make sure you have the required Python packages installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40021a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for Milvus and LLM operations (Python 3.13.9 compatible - Latest versions)\n",
    "!pip install pymilvus>=2.4.8\n",
    "!pip install openai>=1.54.0\n",
    "!pip install langchain>=0.3.7\n",
    "!pip install langchain-openai>=0.2.8\n",
    "!pip install tiktoken>=0.8.0\n",
    "!pip install transformers>=4.46.0\n",
    "!pip install pandas>=2.2.3\n",
    "!pip install pdfminer.six>=20231228\n",
    "!pip install numpy>=1.26.4\n",
    "\n",
    "!pip install langchain-huggingface>=0.1.0 \n",
    "!pip install sentence-transformers>=3.0.0 \n",
    "!pip install torch>=2.0.0  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7264304b",
   "metadata": {},
   "source": [
    "## Step 1: Connect to Milvus\n",
    "Let's start by connecting to your local Milvus instance. We'll use the `pymilvus` library for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b19172b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('default', None),\n",
       " ('tutorial_conn',\n",
       "  <pymilvus.client.grpc_handler.GrpcHandler at 0x259fe9fb6b0>)]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to Milvus (tutorial connection)\n",
    "from pymilvus import connections\n",
    "\n",
    "# Add a named connection for tutorial purposes\n",
    "connections.add_connection(\n",
    "    tutorial_conn={\n",
    "        \"host\": \"localhost\",\n",
    "        \"port\": \"19530\",\n",
    "        \"username\": \"\",\n",
    "        \"password\": \"\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Connect using the tutorial connection name\n",
    "connections.connect(\"tutorial_conn\")\n",
    "\n",
    "# List all active connections\n",
    "connections.list_connections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ad5529",
   "metadata": {},
   "source": [
    "## Step 2: Create a Database and User\n",
    "Now, let's create a new database and a user for our tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f019b572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current databases: ['default']\n",
      "Creating database: tutorial_courses_db\n"
     ]
    }
   ],
   "source": [
    "# Database operations for the tutorial\n",
    "from pymilvus import db\n",
    "\n",
    "# Get current list of databases available to the connection\n",
    "tutorial_dbs = db.list_database(using='tutorial_conn')\n",
    "print('Current databases:', tutorial_dbs)\n",
    "\n",
    "tutorial_db_name = 'tutorial_courses_db'\n",
    "\n",
    "if tutorial_db_name not in tutorial_dbs:\n",
    "    print('Creating database:', tutorial_db_name)\n",
    "    tutorial_db = db.create_database(tutorial_db_name, using='tutorial_conn')\n",
    "\n",
    "# Switch to use the new database\n",
    "db.using_database(tutorial_db_name, using='tutorial_conn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "663dc689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current user list: ['root']\n",
      "Role public exists? True\n"
     ]
    }
   ],
   "source": [
    "# User management for the tutorial\n",
    "from pymilvus import Role, utility\n",
    "\n",
    "current_users = utility.list_usernames(using='tutorial_conn')\n",
    "print('Current user list:', current_users)\n",
    "\n",
    "tutorial_user = 'tutorial_student'\n",
    "\n",
    "if tutorial_user not in current_users:\n",
    "    utility.create_user(tutorial_user, 'tutorial_password', using='tutorial_conn')\n",
    "\n",
    "# Assign a role to the user\n",
    "student_role = Role('public', using='tutorial_conn')\n",
    "print('Role public exists?', student_role.is_exist())\n",
    "\n",
    "# Add user to role\n",
    "student_role.add_user(tutorial_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115054b3",
   "metadata": {},
   "source": [
    "## Step 3: Create a Collection\n",
    "Let's define a collection to store course information and their vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60714e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import CollectionSchema, FieldSchema, DataType, Collection\n",
    "import json\n",
    "\n",
    "# Define fields for the tutorial collection (updated with latest field specifications)\n",
    "course_id_field = FieldSchema(\n",
    "    name='tutorial_series_ID',\n",
    "    dtype=DataType.INT64,\n",
    "    is_primary=True,\n",
    "    auto_id=False  # Explicit specification for clarity\n",
    ")\n",
    "\n",
    "course_title_field = FieldSchema(\n",
    "    name='series',\n",
    "    dtype=DataType.VARCHAR,\n",
    "    max_length=256\n",
    ")\n",
    "\n",
    "course_desc_field = FieldSchema(\n",
    "    name='series_description',\n",
    "    dtype=DataType.VARCHAR,\n",
    "    max_length=2048\n",
    ")\n",
    "\n",
    "embedding_field = FieldSchema(\n",
    "    name='description_embedding',\n",
    "    dtype=DataType.FLOAT_VECTOR,\n",
    "    dim=1536,  # OpenAI text-embedding-3-small dimension\n",
    "    description=\"Vector embeddings for course descriptions\"\n",
    ")\n",
    "\n",
    "# Define schema with updated parameters\n",
    "tutorial_schema = CollectionSchema(\n",
    "    fields=[course_id_field, course_title_field, course_desc_field, embedding_field],\n",
    "    description='Tutorial Series Collection with Vector Embeddings',\n",
    "    enable_dynamic_field=True,\n",
    "    auto_id=False  # Explicit control over ID generation\n",
    ")\n",
    "\n",
    "tutorial_collection_name = 'tutorials_collection'\n",
    "\n",
    "# Create the collection with updated parameters\n",
    "tutorial_collection = Collection(\n",
    "    name=tutorial_collection_name,\n",
    "    schema=tutorial_schema,\n",
    "    using='tutorial_conn',\n",
    "    shards_num=2,\n",
    "    consistency_level=\"Strong\"  # Explicit consistency level\n",
    ")\n",
    "\n",
    "from pymilvus import utility\n",
    "# List all collections\n",
    "print('Current collections:', utility.list_collections(using='tutorial_conn'))\n",
    "\n",
    "# Setup existing collection into another object\n",
    "r_collection = Collection(tutorial_collection_name, using='tutorial_conn')\n",
    "print('\\nCollection Schema:')\n",
    "print(r_collection.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "84d2b292-1d61-47d9-9f2b-f761a21a59da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current collections: []\n",
      "Collection \"tutorials_collection_local\" created successfully for local embeddings!\n",
      "Updated collections: ['tutorials_collection_local']\n"
     ]
    }
   ],
   "source": [
    "# Alternative Collection Schema for Local Embeddings (384 dimensions)\n",
    "# Use this cell if you're using the local HuggingFace embedding model\n",
    "\n",
    "from pymilvus import CollectionSchema, FieldSchema, DataType, Collection, utility\n",
    "import json\n",
    "\n",
    "# Define fields for the tutorial collection (for local embeddings - 384 dimensions)\n",
    "course_id_field_local = FieldSchema(\n",
    "    name='tutorial_series_ID',\n",
    "    dtype=DataType.INT64,\n",
    "    is_primary=True,\n",
    "    auto_id=False\n",
    ")\n",
    "\n",
    "course_title_field_local = FieldSchema(\n",
    "    name='series',\n",
    "    dtype=DataType.VARCHAR,\n",
    "    max_length=256\n",
    ")\n",
    "\n",
    "course_desc_field_local = FieldSchema(\n",
    "    name='series_description',\n",
    "    dtype=DataType.VARCHAR,\n",
    "    max_length=2048\n",
    ")\n",
    "\n",
    "embedding_field_local = FieldSchema(\n",
    "    name='description_embedding',\n",
    "    dtype=DataType.FLOAT_VECTOR,\n",
    "    dim=384,  # HuggingFace all-MiniLM-L6-v2 dimension\n",
    "    description=\"Vector embeddings for course descriptions (local model)\"\n",
    ")\n",
    "\n",
    "# Define schema for local embeddings\n",
    "tutorial_schema_local = CollectionSchema(\n",
    "    fields=[course_id_field_local, course_title_field_local, course_desc_field_local, embedding_field_local],\n",
    "    description='Tutorial Series Collection with Local Vector Embeddings',\n",
    "    enable_dynamic_field=True,\n",
    "    auto_id=False\n",
    ")\n",
    "\n",
    "tutorial_collection_name_local = 'tutorials_collection_local'\n",
    "\n",
    "# Check if collection already exists and drop it if needed\n",
    "existing_collections = utility.list_collections(using='tutorial_conn')\n",
    "print('Current collections:', existing_collections)\n",
    "\n",
    "if tutorial_collection_name_local in existing_collections:\n",
    "    print(f'Collection \"{tutorial_collection_name_local}\" already exists. Dropping it...')\n",
    "    utility.drop_collection(tutorial_collection_name_local, using='tutorial_conn')\n",
    "    print('Collection dropped successfully.')\n",
    "\n",
    "# Create the collection for local embeddings\n",
    "tutorial_collection_local = Collection(\n",
    "    name=tutorial_collection_name_local,\n",
    "    schema=tutorial_schema_local,\n",
    "    using='tutorial_conn',\n",
    "    shards_num=2,\n",
    "    consistency_level=\"Strong\"\n",
    ")\n",
    "\n",
    "print(f'Collection \"{tutorial_collection_name_local}\" created successfully for local embeddings!')\n",
    "print('Updated collections:', utility.list_collections(using='tutorial_conn'))\n",
    "\n",
    "# Use this collection for the rest of the tutorial if using local embeddings\n",
    "tutorial_collection = tutorial_collection_local\n",
    "tutorial_collection_name = tutorial_collection_name_local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240ae71b",
   "metadata": {},
   "source": [
    "## Step 4: Insert Data into Milvus\n",
    "Let's load some example course data and insert it into our collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "cbe3c576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tutorial Series ID</th>\n",
       "      <th>Playlist</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Its all about CMD</td>\n",
       "      <td>Learn the power of the Command Line Interface ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MS Excel Course - Begineer &amp; Intermediate Users</td>\n",
       "      <td>Build a strong foundation in Excel, starting f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Image Processing With OpenCV in Python</td>\n",
       "      <td>Dive into image processing using OpenCV and Py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>DSA - Interview Preparation Series</td>\n",
       "      <td>A focused series on Data Structures and Algori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Deep Learning- Single Image Super Resolution</td>\n",
       "      <td>Explore how deep learning can enhance image qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tutorial Series ID                                         Playlist  \\\n",
       "0                   1                                Its all about CMD   \n",
       "1                   2  MS Excel Course - Begineer & Intermediate Users   \n",
       "2                   3           Image Processing With OpenCV in Python   \n",
       "3                   4               DSA - Interview Preparation Series   \n",
       "4                   5     Deep Learning- Single Image Super Resolution   \n",
       "\n",
       "                                         Description  \n",
       "0  Learn the power of the Command Line Interface ...  \n",
       "1  Build a strong foundation in Excel, starting f...  \n",
       "2  Dive into image processing using OpenCV and Py...  \n",
       "3  A focused series on Data Structures and Algori...  \n",
       "4  Explore how deep learning can enhance image qu...  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the input tutorial series CSV\n",
    "import pandas as pd\n",
    "tutorial_series = pd.read_csv(\"TutorialSeries-Descriptions.csv\")\n",
    "tutorial_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c74ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use langchain-openai for embeddings (latest API syntax)\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "# Setup OpenAI API key for embedding generation\n",
    "openai_api_key = 'your-openai-api-key-here'  # Replace with your own key\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "\n",
    "# Initialize with latest model and explicit parameters\n",
    "embeddings_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    dimensions=1536,  # Explicit dimension specification\n",
    "    show_progress_bar=True,  # Show progress for batch operations\n",
    ")\n",
    "print(\"OpenAI Embedding model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea5ce42-0c8a-4d1d-98af-639ea690d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI setup (updated import and latest API)\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "# Azure-specific setup - IMPORTANT: Replace with your actual credentials\n",
    "azure_api_key = 'your-azure-api-key-here'  # Replace with your Azure OpenAI key\n",
    "azure_endpoint = 'https://your-resource.openai.azure.com/'  # Replace with your Azure endpoint\n",
    "azure_deployment_name = 'your-deployment-name'  # Replace with your model's deployment name\n",
    "\n",
    "# Set the environment variables for Azure OpenAI\n",
    "os.environ['AZURE_OPENAI_API_KEY'] = azure_api_key\n",
    "os.environ['AZURE_OPENAI_ENDPOINT'] = azure_endpoint\n",
    "\n",
    "# Initialize the embedding model for Azure (latest API version)\n",
    "embeddings_model = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=azure_deployment_name,\n",
    "    openai_api_version=\"2024-10-21\",  # Latest API version\n",
    "    model=\"text-embedding-3-small\",  # Specify model explicitly\n",
    ")\n",
    "\n",
    "print(\"Azure Embedding model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a7427ddc-4369-46ec-8413-895f922deb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10 tutorial descriptions...\n",
      "Attempting to use transformers directly...\n",
      "Loading tokenizer and model: sentence-transformers/all-MiniLM-L6-v2\n",
      "Direct transformers failed: \n",
      "AutoModel requires the PyTorch library but it was not found in your environment. Check out the instructions on the\n",
      "installation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\n",
      "Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Attempting sentence-transformers with compatibility fix...\n",
      "Sentence-transformers with fix failed: name 'LRScheduler' is not defined\n",
      "Using improved TF-IDF embeddings (no downloads required)...\n",
      "Improved text embedding model initialized (no downloads required)\n",
      "Built vocabulary with 39 informative words\n",
      "Generating embedding 1/10: Learn the power of the Command Line Interface CMD ...\n",
      "Generating embedding 2/10: Build a strong foundation in Excel, starting from ...\n",
      "Generating embedding 3/10: Dive into image processing using OpenCV and Python...\n",
      "Generating embedding 4/10: A focused series on Data Structures and Algorithms...\n",
      "Generating embedding 5/10: Explore how deep learning can enhance image qualit...\n",
      "Generating embedding 6/10: Learn how computer vision enables lane detection i...\n",
      "Generating embedding 7/10: Unlock the power of Azure OpenAI services to integ...\n",
      "Generating embedding 8/10: Get started with Azure Machine Learning and unders...\n",
      "Generating embedding 9/10: Master the basics of automation testing using Sele...\n",
      "Generating embedding 10/10: Learn how to build, deploy, and scale modern web a...\n",
      "Generated 10 embeddings successfully!\n",
      "\n",
      "Embedding Quality Check:\n",
      "Sample similarity between embeddings 1 and 2: 0.1420\n",
      "Sample distance (1 - similarity): 0.8580\n",
      "\n",
      "Data verification:\n",
      "  IDs: 10\n",
      "  Titles: 10\n",
      "  Descriptions: 10\n",
      "  Embeddings: 10\n",
      "  Embedding dimensions: 384\n",
      "\n",
      "IMPORTANT: You're using 384-dimensional embeddings!\n",
      "   Make sure your collection schema uses dim=384, not dim=1536\n",
      "   Run the 'Alternative Collection Schema' cell (cell 10) if you haven't already\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for insert (with compatible local embedding model)\n",
    "tutorial_ids = tutorial_series['Tutorial Series ID'].tolist()\n",
    "tutorial_titles = tutorial_series['Playlist'].tolist()\n",
    "tutorial_descriptions = tutorial_series['Description'].tolist()\n",
    " \n",
    "print(f\"Processing {len(tutorial_descriptions)} tutorial descriptions...\")\n",
    " \n",
    "# Try different embedding approaches in order of preference\n",
    "embeddings_model = None\n",
    " \n",
    "# Option 1: Try direct transformers (most compatible)\n",
    "try:\n",
    "    print(\"Attempting to use transformers directly...\")\n",
    "    from transformers import AutoTokenizer, AutoModel\n",
    "    import torch\n",
    "    import numpy as np\n",
    "   \n",
    "    class DirectTransformersEmbeddings:\n",
    "        def __init__(self):\n",
    "            self.model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "            print(f\"Loading tokenizer and model: {self.model_name}\")\n",
    "           \n",
    "            # Load tokenizer and model directly\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "            self.model = AutoModel.from_pretrained(self.model_name)\n",
    "           \n",
    "            # Set device\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            self.model.to(self.device)\n",
    "            self.model.eval()  # Set to evaluation mode\n",
    "           \n",
    "            print(f\"Direct transformers model loaded on {self.device}\")\n",
    "            print(\"This model produces 384-dimensional embeddings\")\n",
    "       \n",
    "        def embed_query(self, text):\n",
    "            # Tokenize\n",
    "            inputs = self.tokenizer(\n",
    "                text,\n",
    "                return_tensors='pt',\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=512\n",
    "            )\n",
    "           \n",
    "            # Move to device\n",
    "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "           \n",
    "            # Generate embeddings\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "               \n",
    "                # Mean pooling\n",
    "                attention_mask = inputs['attention_mask']\n",
    "                token_embeddings = outputs.last_hidden_state\n",
    "                input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "                embeddings = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "               \n",
    "                # Normalize\n",
    "                embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "           \n",
    "            return embeddings.cpu().numpy()[0].tolist()\n",
    "   \n",
    "    embeddings_model = DirectTransformersEmbeddings()\n",
    "   \n",
    "except Exception as e:\n",
    "    print(f\"Direct transformers failed: {e}\")\n",
    "   \n",
    "    # Option 2: Try sentence-transformers with compatibility fix\n",
    "    try:\n",
    "        print(\"Attempting sentence-transformers with compatibility fix...\")\n",
    "       \n",
    "        # Try to fix the LRScheduler issue\n",
    "        import torch.optim.lr_scheduler as lr_scheduler\n",
    "        if not hasattr(lr_scheduler, 'LRScheduler'):\n",
    "            # For older PyTorch versions, LRScheduler might be named differently\n",
    "            if hasattr(lr_scheduler, '_LRScheduler'):\n",
    "                lr_scheduler.LRScheduler = lr_scheduler._LRScheduler\n",
    "            else:\n",
    "                # Create a dummy LRScheduler class\n",
    "                class LRScheduler:\n",
    "                    def __init__(self, *args, **kwargs):\n",
    "                        pass\n",
    "                lr_scheduler.LRScheduler = LRScheduler\n",
    "       \n",
    "        from sentence_transformers import SentenceTransformer\n",
    "       \n",
    "        class HuggingFaceEmbeddings:\n",
    "            def __init__(self):\n",
    "                self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "                print(\"HuggingFace SentenceTransformer model loaded successfully!\")\n",
    "                print(\"This model produces 384-dimensional embeddings\")\n",
    "           \n",
    "            def embed_query(self, text):\n",
    "                embedding = self.model.encode(text, normalize_embeddings=True)\n",
    "                return embedding.tolist()\n",
    "       \n",
    "        embeddings_model = HuggingFaceEmbeddings()\n",
    "       \n",
    "    except Exception as e:\n",
    "        print(f\"Sentence-transformers with fix failed: {e}\")\n",
    " \n",
    "# Option 3: Fallback to improved TF-IDF if all else fails\n",
    "if embeddings_model is None:\n",
    "    print(\"Using improved TF-IDF embeddings (no downloads required)...\")\n",
    "   \n",
    "    import numpy as np\n",
    "    from collections import Counter\n",
    "    import re\n",
    "    import math\n",
    " \n",
    "    class ImprovedTextEmbeddings:\n",
    "        def __init__(self, dimension=384):\n",
    "            self.dimension = dimension\n",
    "            self.vocabulary = {}\n",
    "            self.idf_scores = {}\n",
    "            print(\"Improved text embedding model initialized (no downloads required)\")\n",
    "       \n",
    "        def preprocess_text(self, text):\n",
    "            text = text.lower()\n",
    "            text = re.sub(r'[^\\w\\s-]', ' ', text)\n",
    "            words = [word for word in text.split() if len(word) > 2]\n",
    "            return words\n",
    "       \n",
    "        def build_vocabulary(self, texts):\n",
    "            all_words = []\n",
    "            for text in texts:\n",
    "                words = self.preprocess_text(text)\n",
    "                all_words.extend(words)\n",
    "           \n",
    "            word_counts = Counter(all_words)\n",
    "            stop_words = {'the', 'and', 'for', 'are', 'with', 'this', 'that', 'you', 'can', 'how', 'use', 'will', 'from', 'all'}\n",
    "            filtered_words = {word: count for word, count in word_counts.items()\n",
    "                             if word not in stop_words and count > 1}\n",
    "           \n",
    "            self.vocabulary = {word: idx for idx, (word, _) in enumerate(\n",
    "                sorted(filtered_words.items(), key=lambda x: x[1], reverse=True)[:self.dimension])}\n",
    "           \n",
    "            doc_count = len(texts)\n",
    "            for word in self.vocabulary:\n",
    "                doc_freq = sum(1 for text in texts if word in self.preprocess_text(text))\n",
    "                self.idf_scores[word] = math.log((doc_count + 1) / (doc_freq + 1)) + 1\n",
    "           \n",
    "            print(f\"Built vocabulary with {len(self.vocabulary)} informative words\")\n",
    "       \n",
    "        def embed_query(self, text):\n",
    "            words = self.preprocess_text(text)\n",
    "            word_counts = Counter(words)\n",
    "           \n",
    "            vector = np.zeros(self.dimension)\n",
    "           \n",
    "            for word, count in word_counts.items():\n",
    "                if word in self.vocabulary:\n",
    "                    idx = self.vocabulary[word]\n",
    "                    tf = 1 + math.log(count) if count > 0 else 0\n",
    "                    tfidf = tf * self.idf_scores.get(word, 0)\n",
    "                    vector[idx] = tfidf\n",
    "           \n",
    "            # Add small random noise to prevent identical vectors\n",
    "            noise = np.random.normal(0, 0.001, self.dimension)\n",
    "            vector = vector + noise\n",
    "           \n",
    "            norm = np.linalg.norm(vector)\n",
    "            if norm > 0:\n",
    "                vector = vector / norm\n",
    "            else:\n",
    "                vector = np.random.normal(0, 0.01, self.dimension)\n",
    "                vector = vector / np.linalg.norm(vector)\n",
    "           \n",
    "            return vector.tolist()\n",
    " \n",
    "    embeddings_model = ImprovedTextEmbeddings(dimension=384)\n",
    "    embeddings_model.build_vocabulary(tutorial_descriptions)\n",
    " \n",
    "# Generate embeddings with progress tracking\n",
    "desc_embeddings = []\n",
    "for i, desc in enumerate(tutorial_descriptions, 1):\n",
    "    print(f\"Generating embedding {i}/{len(tutorial_descriptions)}: {desc[:50]}...\")\n",
    "    embedding = embeddings_model.embed_query(desc)\n",
    "    desc_embeddings.append(embedding)\n",
    " \n",
    "print(f\"Generated {len(desc_embeddings)} embeddings successfully!\")\n",
    " \n",
    "# Check embedding quality\n",
    "print(\"\\nEmbedding Quality Check:\")\n",
    "if len(desc_embeddings) >= 2:\n",
    "    import numpy as np\n",
    "    emb1 = np.array(desc_embeddings[0])\n",
    "    emb2 = np.array(desc_embeddings[1])\n",
    "    similarity = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
    "    print(f\"Sample similarity between embeddings 1 and 2: {similarity:.4f}\")\n",
    "    print(f\"Sample distance (1 - similarity): {1 - similarity:.4f}\")\n",
    " \n",
    "# Verify data consistency\n",
    "print(f\"\\nData verification:\")\n",
    "print(f\"  IDs: {len(tutorial_ids)}\")\n",
    "print(f\"  Titles: {len(tutorial_titles)}\")  \n",
    "print(f\"  Descriptions: {len(tutorial_descriptions)}\")\n",
    "print(f\"  Embeddings: {len(desc_embeddings)}\")\n",
    "print(f\"  Embedding dimensions: {len(desc_embeddings[0]) if desc_embeddings else 'N/A'}\")\n",
    " \n",
    "# Format for data input\n",
    "insert_data = [tutorial_ids, tutorial_titles, tutorial_descriptions, desc_embeddings]\n",
    " \n",
    "# Important note about dimensions\n",
    "if desc_embeddings and len(desc_embeddings[0]) == 384:\n",
    "    print(\"\\nIMPORTANT: You're using 384-dimensional embeddings!\")\n",
    "    print(\"   Make sure your collection schema uses dim=384, not dim=1536\")\n",
    "    print(\"   Run the 'Alternative Collection Schema' cell (cell 10) if you haven't already\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d6af716c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting data into collection...\n",
      "Insert result: (insert count: 10, delete count: 0, upsert count: 0, timestamp: 461808329323708417, success count: 10, err count: 0\n",
      "Inserted 10 records successfully!\n",
      "Flushing data to storage...\n",
      "Data flushed successfully!\n",
      "Total entities in collection: 20\n"
     ]
    }
   ],
   "source": [
    "# Insert data into the tutorial collection (with error handling)\n",
    "tutorial_collection = Collection(tutorial_collection_name, using='tutorial_conn')\n",
    "\n",
    "try:\n",
    "    print(\"Inserting data into collection...\")\n",
    "    mr = tutorial_collection.insert(insert_data)\n",
    "    print(f\"Insert result: {mr}\")\n",
    "    print(f\"Inserted {mr.insert_count} records successfully!\")\n",
    "    \n",
    "    # Flush the data after insert\n",
    "    print('Flushing data to storage...')\n",
    "    tutorial_collection.flush(timeout=180)\n",
    "    print('Data flushed successfully!')\n",
    "    \n",
    "    # Verify the data was inserted\n",
    "    print(f\"Total entities in collection: {tutorial_collection.num_entities}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during insertion: {e}\")\n",
    "    print(\"Please check your data format and collection schema.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3361f836",
   "metadata": {},
   "source": [
    "## Step 5: Build an Index\n",
    "Let's build an index on the embedding field to enable fast vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "92e9d4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index building progress: {'total_rows': 20, 'indexed_rows': 20, 'pending_index_rows': 0, 'state': 'Finished'}\n"
     ]
    }
   ],
   "source": [
    "# Build an index for the embedding field (updated with latest parameters)\n",
    "index_params = {\n",
    "    'metric_type': 'COSINE', \n",
    "    'index_type': 'HNSW',     \n",
    "    'params': {\n",
    "        'M': 16,              # Number of connections for HNSW\n",
    "        'efConstruction': 200  # Size of dynamic candidate list for HNSW\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create index with progress tracking\n",
    "tutorial_collection.create_index(\n",
    "    field_name='description_embedding',\n",
    "    index_params=index_params,\n",
    "    timeout=None  # Allow unlimited time for large datasets\n",
    ")\n",
    "\n",
    "# Check index building progress\n",
    "progress = utility.index_building_progress(tutorial_collection_name, using='tutorial_conn')\n",
    "print(f\"Index building progress: {progress}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54436240",
   "metadata": {},
   "source": [
    "## Step 6: Query Scalar Data\n",
    "Let's query the collection for a specific course by its ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "195dd34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tutorial collection loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load the collection into memory before querying\n",
    "tutorial_collection.load()\n",
    "print('Tutorial collection loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7f687494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [\"{'series': 'Its all about CMD', 'series_description': 'Learn the power of the Command Line Interface CMD to navigate, manage files, and automate tasks on Windows. This series covers essential commands and practical use cases for beginners. Ideal for those looking to boost productivity and troubleshoot systems efficiently.', 'tutorial_series_ID': 1}\"], extra_info: {}\n",
      "\n",
      "Result object: <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Query for a specific course by ID (fixed field name)\n",
    "result = tutorial_collection.query(\n",
    "    expr='tutorial_series_ID == 1',\n",
    "    output_fields=['series', 'series_description']\n",
    ")\n",
    "print(result)\n",
    "if result:\n",
    "    print('\\nResult object:', type(result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5ddd71d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [], extra_info: {}\n"
     ]
    }
   ],
   "source": [
    "# Query for tutorial with title containing 'Azure' and ID > 5\n",
    "result2 = tutorial_collection.query(\n",
    "    expr='(series like \"Azure\") and (tutorial_series_ID > 5)',\n",
    "    output_fields=['series', 'series_description']\n",
    ")\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725a9341",
   "metadata": {},
   "source": [
    "## Step 7: Search Vector Fields\n",
    "Let's search for courses using vector similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "6e5dac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for: excel\n",
      "Search result type: <class 'pymilvus.client.search_result.HybridHits'> \n",
      "\n",
      "1. ID: 5, Distance: 0.0659\n",
      "   Series: Deep Learning- Single Image Super Resolution\n",
      "   Description: Explore how deep learning can enhance image quality using Single Image Super Resolution SISR. Learn ...\n",
      "\n",
      "2. ID: 4, Distance: 0.0520\n",
      "   Series: DSA - Interview Preparation Series\n",
      "   Description: A focused series on Data Structures and Algorithms DSA designed to help you crack technical intervie...\n",
      "\n",
      "3. ID: 8, Distance: 0.0459\n",
      "   Series: Azure ML Essentials\n",
      "   Description: Get started with Azure Machine Learning and understand its core services. Learn to build, train, and...\n",
      "\n",
      "4. ID: 10, Distance: 0.0201\n",
      "   Series: .NET Core Web Applications with Azure \n",
      "   Description: Learn how to build, deploy, and scale modern web applications using .NET Core and Azure services. Co...\n",
      "\n",
      "5. ID: 9, Distance: 0.0200\n",
      "   Series: Autoamtion Testing Essentials - Selenium and Playwright\n",
      "   Description: Master the basics of automation testing using Selenium and Playwright. This series teaches how to wr...\n",
      "\n",
      "6. ID: 2, Distance: 0.0157\n",
      "   Series: MS Excel Course - Begineer & Intermediate Users\n",
      "   Description: Build a strong foundation in Excel, starting from basic functions to more advanced tools like PivotT...\n",
      "\n",
      "7. ID: 3, Distance: 0.0037\n",
      "   Series: Image Processing With OpenCV in Python\n",
      "   Description: Dive into image processing using OpenCV and Python. Learn how to read, modify, and analyze images an...\n",
      "\n",
      "8. ID: 7, Distance: -0.0077\n",
      "   Series: Mastering Azure Open AI\n",
      "   Description: Unlock the power of Azure OpenAI services to integrate intelligent language models into your apps. L...\n",
      "\n",
      "9. ID: 1, Distance: -0.0344\n",
      "   Series: Its all about CMD\n",
      "   Description: Learn the power of the Command Line Interface CMD to navigate, manage files, and automate tasks on W...\n",
      "\n",
      "10. ID: 6, Distance: -0.0816\n",
      "   Series: Image Processing- Lane detection and Autonomous Driving\n",
      "   Description: Learn how computer vision enables lane detection in self-driving cars. This series covers edge detec...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search for courses similar to a query string (updated search parameters)\n",
    "search_params = {\n",
    "    'metric_type': 'COSINE',  # Match the index metric type\n",
    "    'offset': 0,\n",
    "    'ignore_growing': False,\n",
    "    'params': {\n",
    "        'ef': 64  # Search parameter for HNSW index\n",
    "    }\n",
    "}\n",
    "\n",
    "search_string = 'excel'\n",
    "search_embed = embeddings_model.embed_query(search_string)\n",
    "\n",
    "search_results = tutorial_collection.search(\n",
    "    data=[search_embed],\n",
    "    anns_field='description_embedding',\n",
    "    param=search_params,\n",
    "    limit=10,\n",
    "    expr=None,\n",
    "    output_fields=['series', 'series_description'],  # Include description in output\n",
    "    consistency_level='Strong',\n",
    "    round_decimal=4  # Round distances to 4 decimal places\n",
    ")\n",
    "\n",
    "print('Search results for:', search_string)\n",
    "print('Search result type:', type(search_results[0]), '\\n')\n",
    "for i, result in enumerate(search_results[0], 1):\n",
    "    print(f\"{i}. ID: {result.id}, Distance: {result.distance:.4f}\")\n",
    "    print(f\"   Series: {result.entity.get('series')}\")\n",
    "    print(f\"   Description: {result.entity.get('series_description')[:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "973415fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for: best movies of the year\n",
      "(Note: Higher distances indicate less similarity)\n",
      "\n",
      "1. ID: 2, Distance: -0.0014\n",
      "   Series: MS Excel Course - Begineer & Intermediate Users\n",
      "   Description: Build a strong foundation in Excel, starting from basic functions to more advanced tools like PivotT...\n",
      "\n",
      "2. ID: 4, Distance: -0.0016\n",
      "   Series: DSA - Interview Preparation Series\n",
      "   Description: A focused series on Data Structures and Algorithms DSA designed to help you crack technical intervie...\n",
      "\n",
      "3. ID: 6, Distance: -0.0128\n",
      "   Series: Image Processing- Lane detection and Autonomous Driving\n",
      "   Description: Learn how computer vision enables lane detection in self-driving cars. This series covers edge detec...\n",
      "\n",
      "4. ID: 1, Distance: -0.0194\n",
      "   Series: Its all about CMD\n",
      "   Description: Learn the power of the Command Line Interface CMD to navigate, manage files, and automate tasks on W...\n",
      "\n",
      "5. ID: 3, Distance: -0.0209\n",
      "   Series: Image Processing With OpenCV in Python\n",
      "   Description: Dive into image processing using OpenCV and Python. Learn how to read, modify, and analyze images an...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search for an unrelated query (updated with better formatting)\n",
    "search_string2 = 'best movies of the year'\n",
    "search_embed2 = embeddings_model.embed_query(search_string2)\n",
    "\n",
    "search_results2 = tutorial_collection.search(\n",
    "    data=[search_embed2],\n",
    "    anns_field='description_embedding',\n",
    "    param=search_params,\n",
    "    limit=5,  # Reduced limit for cleaner output\n",
    "    expr=None,\n",
    "    output_fields=['series', 'series_description'],\n",
    "    consistency_level='Strong',\n",
    "    round_decimal=4\n",
    ")\n",
    "\n",
    "print('Search results for:', search_string2)\n",
    "print('(Note: Higher distances indicate less similarity)\\n')\n",
    "for i, result in enumerate(search_results2[0], 1):\n",
    "    print(f\"{i}. ID: {result.id}, Distance: {result.distance:.4f}\")\n",
    "    print(f\"   Series: {result.entity.get('series')}\")\n",
    "    print(f\"   Description: {result.entity.get('series_description')[:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca83136",
   "metadata": {},
   "source": [
    "## Step 8: Delete Objects and Entities\n",
    "Let's see how to delete records and collections in Milvus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "5a405edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(insert count: 0, delete count: 1, upsert count: 0, timestamp: 461808405038235652, success count: 0, err count: 0"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete a single record by course ID (fixed field name)\n",
    "tutorial_collection.delete('tutorial_series_ID in [2]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a03cd7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the collection\n",
    "utility.drop_collection(tutorial_collection_name, using='tutorial_conn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "db00d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the database (make sure all collections are dropped first)\n",
    "db.drop_database(tutorial_db_name, using='tutorial_conn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c699948",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Troubleshooting Tips\n",
    "\n",
    "If you encounter any issues:\n",
    "\n",
    "1. **Connection Issues**: Make sure Milvus is running on `localhost:19530`\n",
    "   - Check if Docker containers are running: `docker ps`\n",
    "   - Restart Milvus if needed: `docker-compose restart`\n",
    "\n",
    "2. **API Key Issues**: Replace placeholder API keys with your actual credentials\n",
    "   - OpenAI: Get key from [OpenAI Platform](https://platform.openai.com/api-keys)\n",
    "   - Azure OpenAI: Get key from Azure Portal\n",
    "\n",
    "3. **Package Compatibility**: All packages are updated for Python 3.13.9 compatibility\n",
    "   - Use `pip install --upgrade` if you encounter version conflicts\n",
    "   - Consider using virtual environments for isolation\n",
    "\n",
    "4. **Memory Issues**: Consider reducing batch sizes if working with large datasets\n",
    "   - Process embeddings in smaller batches\n",
    "   - Increase system memory or use cloud instances\n",
    "\n",
    "5. **Index Performance**: HNSW index provides better performance than IVF_FLAT\n",
    "   - Adjust `M` and `efConstruction` parameters based on your dataset size\n",
    "   - Use COSINE metric for embeddings instead of L2\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this updated tutorial, you learned how to:\n",
    "- ✅ Connect to Milvus and manage databases/users\n",
    "- ✅ Create collections with vector fields using latest schema options\n",
    "- ✅ Insert data with embeddings and progress tracking\n",
    "- ✅ Build efficient HNSW indexes for vector search\n",
    "- ✅ Query both scalar and vector data with improved search parameters\n",
    "- ✅ Clean up resources properly\n",
    "\n",
    "### Key Updates for Python 3.13.9:\n",
    "- **Latest package versions** with compatibility guarantees\n",
    "- **Improved embedding models** (text-embedding-3-small)\n",
    "- **Better index types** (HNSW instead of IVF_FLAT)\n",
    "- **Enhanced error handling** and progress tracking\n",
    "- **Optimized search parameters** for better performance\n",
    "\n",
    "The notebook is now fully compatible with **Python 3.13.9** and uses the latest available package versions! 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57ac7c9-9751-4faf-ba52-99e8f0377778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
